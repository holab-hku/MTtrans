{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add /ssd/users/wergillius/Project/MTtrans to path\n",
      "/ssd/users/wergillius/Project/MTtrans\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PATH\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(0)\n",
    "import torch\n",
    "import utils\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm\n",
    "from models import reader\n",
    "from models.popen import Auto_popen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pj = lambda x: os.path.join(utils.script_dir, x)\n",
    "dpj = lambda x: os.path.join(utils.data_dir, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define some function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_load_data(config_file, device, kfold_index):\n",
    "    loader_set = {}                                                                                                                                                                                                                                                                                                                 \n",
    "    base_path = ['cycle_train_val.csv', 'cycle_test.csv']\n",
    "    base_csv = 'cycle_MTL_transfer.csv'\n",
    "    POPEN = Auto_popen(pj(config_file))\n",
    "\n",
    "    for subset in POPEN.cycle_set:\n",
    "        if (subset in ['MPA_U', 'MPA_H', 'MPA_V', 'SubMPA_H']):\n",
    "            datapopen = Auto_popen(pj('log/Backbone/RL_hard_share/3M/schedule_lr.ini'))\n",
    "            datapopen.split_like = [path.replace('cycle', subset) for path in base_path]\n",
    "            datapopen.kfold_index = kfold_index\n",
    "            datapopen.shuffle = False\n",
    "            \n",
    "        elif (subset in ['RP_293T', 'RP_muscle', 'RP_PC3']):\n",
    "            datapopen = Auto_popen(pj('log/Backbone/RL_hard_share/3R/schedule_MTL.ini'))\n",
    "            datapopen.csv_path = base_csv.replace('cycle', subset)\n",
    "            datapopen.kfold_index = kfold_index\n",
    "            datapopen.shuffle = False\n",
    "            \n",
    "\n",
    "        # in the order of 0: train , 1: val , 2: test\n",
    "        loader_set[subset] = reader.get_dataloader(datapopen)\n",
    "\n",
    "    return loader_set\n",
    "\n",
    "def reload_model(config_file, device, kfold_index):\n",
    "    \n",
    "    POPEN  = Auto_popen(pj(config_file))\n",
    "    if kfold_index is None:\n",
    "        check_point = torch.load(POPEN.vae_pth_path, map_location=device)\n",
    "    else:\n",
    "        check_point = torch.load(\n",
    "            POPEN.vae_pth_path.replace('.pth', '_cv%d.pth'%kfold_index),\n",
    "            map_location=device)\n",
    "        \n",
    "    model = check_point['state_dict'].to(device)\n",
    "    return model\n",
    "\n",
    "def val_a_epoch(model, dataloader, device):\n",
    "    y_true_ls = []\n",
    "    y_pred_ls = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X,Y in dataloader:\n",
    "            X = X.float().to(device)\n",
    "            y_true_ls.append(Y.cpu().numpy())\n",
    "\n",
    "            y_pred = model(X)\n",
    "            y_pred_ls.append(y_pred.cpu().numpy())\n",
    "    \n",
    "    y_true_f = np.concatenate( y_true_ls).flatten()\n",
    "    y_pred_f = np.concatenate( y_pred_ls).flatten()\n",
    "    \n",
    "    return y_true_f, y_pred_f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pipeline(config_path , which_set, cv_k_list, device=0):\n",
    "\n",
    "    POPEN = Auto_popen(pj(config_path))\n",
    "\n",
    "    r2_dict = {task :[] for task in POPEN.cycle_set}\n",
    "    spr_dict = {task :[] for task in POPEN.cycle_set}\n",
    "\n",
    "    for k in cv_k_list:\n",
    "        \n",
    "        model_k = reload_model(config_path, device, k)\n",
    "        loaders = kfold_load_data(config_path,device,k)\n",
    "\n",
    "        for task in POPEN.cycle_set:\n",
    "            model_k.task = task\n",
    "            dataloader = loaders[task][which_set]\n",
    "            true_N_pred = val_a_epoch(model_k, dataloader, device)\n",
    "\n",
    "            # compute and then add to dict\n",
    "            spr_dict[task].append(stats.spearmanr(*true_N_pred)[0])\n",
    "            r2_dict[task].append(r2_score(*true_N_pred))\n",
    "\n",
    "    spr_df = pd.DataFrame(spr_dict)\n",
    "    spr_df.columns = [col+\"_spr\" for col in spr_df.columns]\n",
    "    \n",
    "    r2_df = pd.DataFrame(r2_dict)\n",
    "    r2_df.columns = [col+\"_r2\" for col in r2_df.columns]\n",
    "\n",
    "    result_df = pd.concat([spr_df,r2_df],axis=1)\n",
    "    melt_df = pd.melt(result_df,value_name='performance')\n",
    "    melt_df['model'] = POPEN.run_name\n",
    "    melt_df['task'] = melt_df['variable'].apply(lambda x: x.split(\"_\")[-2])\n",
    "    melt_df['metric'] = melt_df['variable'].apply(lambda x: x.split(\"_\")[-1])\n",
    "    melt_df.loc[:,'which_set'] = ['train','val','test'][which_set]\n",
    "    return melt_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "config_3R = \"log/Backbone/RL_hard_share/3R/schedule_MTL.ini\"\n",
    "\n",
    "df_val_3R = eval_pipeline(config_3R, 1, range(3),device=device)\n",
    "df_test_3R = eval_pipeline(config_3R, 2, range(3),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_3R.loc[:,'model'] = '3R'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ST293 = \"log/Backbone/RL_hard_share/single_task/RP_single_task/ST_293T.ini\"\n",
    "\n",
    "df_test_ST293 = eval_pipeline(config_ST293, 2, range(3),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_STmuscle = \"log/Backbone/RL_hard_share/single_task/RP_single_task/ST_muscle.ini\"\n",
    "\n",
    "df_test_STmuscle = eval_pipeline(config_STmuscle, 2, range(3),device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_STPC3 = \"log/Backbone/RL_hard_share/single_task/RP_single_task/ST_PC3.ini\"\n",
    "\n",
    "df_test_STPC3 = eval_pipeline(config_STPC3, 2, range(3),device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## append all result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellline_prediction_df = pd.DataFrame([])\n",
    "\n",
    "for df in [df_test_3R, df_test_ST293, df_test_STmuscle, df_test_STPC3]:\n",
    "    cellline_prediction_df=cellline_prediction_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cellline_prediction_df.to_csv(\"Performance_TestSet_RP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "522c0aa0229da0f5a0280240b87581e97ce801dee154632d33374fc9d91c016d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
